<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.49" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Laplacian Paradigm 2.0</title>

  
  <link type="text/css" rel="stylesheet" href="https://sachdevasushant.github.io/laplacian2.0/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://sachdevasushant.github.io/laplacian2.0/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://sachdevasushant.github.io/laplacian2.0/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://sachdevasushant.github.io/laplacian2.0/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://sachdevasushant.github.io/laplacian2.0/index.xml" rel="alternate" type="application/rss+xml" title="Laplacian Paradigm 2.0" />

  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://sachdevasushant.github.io/laplacian2.0/"><h1>Laplacian Paradigm 2.0</h1></a>
      <p class="lead">
       FOCS 2018 workshop 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://sachdevasushant.github.io/laplacian2.0/">Summary</a> </li>
        <li><a href="/laplacian2.0/richard/"> 8:40 AM. Merging Continuous and Discrete (Richard Peng) </a></li><li><a href="/laplacian2.0/aaron/"> 9:10 AM. Beyond Laplacian Solvers (Aaron Sidford) </a></li><li><a href="/laplacian2.0/sushant/"> 9:50 AM. Approximate Gaussian Elimination (Sushant Sachdeva) </a></li><li><a href="/laplacian2.0/rasmus/"> 11:00 AM. Analysis using Matrix Martingales (Rasmus Kyng) </a></li><li><a href="/laplacian2.0/aaron_uc/"> 2:00 PM. Algorithmic proofs via Gaussian Elimination (Aaron Schild) </a></li>
      </ul>
    </nav>

  </div>
</aside>

    <main class="content container">
    <div class="posts">
    <p><h1>
<center>Laplacian Paradigm 2.0
 </center>
</h1>
<hr></p>

<p><br>
<big>Date: </big> Saturday, October 6th, 2018.
<br>
<big>Location: </big><a href="https://www.irif.fr/~focs2018/venue/">Amphi Darboux, Institut Henri Poincaré, Paris, France</a>
<br>
<big>Organizers: </big>
Richard Peng (GaTech)
and Sushant Sachdeva (UToronto)
<br>
<big>Synopsis: </big>
<p>Spectral algorithms originated with the use of eigenvalues and eigenvectors to analyze graphs, and have wide applications in machine learning, image processing, and network science. Over the past decade, the synergy of spectral algorithms with tools from scientific computing and combinatorial graph theory has led to the Laplacian paradigm for designing graph algorithms. For a wide range of fundamental graph problems such as max-flow, stationary distributions of random walks, or even shortest paths with general weights, the current best algorithms on sparse graphs utilize ideas related to graph Laplacians.</p>
<p>A common theme among algorithms usually described as ‘spectral algorithms’ – including foundational algorithms in the Laplacian paradigm – has been a clear transition between combinatorial and numerical components. This delineation is exemplified by spectral graph partitioning, which first computes eigenvectors of the graph Laplacian numerically, then clusters them using geometry and combinatorics.</p>
<p>On the other hand, a hallmark of recent progresses in linear systems, optimization, and numerical problems broadly related to graph Laplacians is a tighter, more fine-grained integration of combinatorial and numerical components. These algorithms are built on deeper understanding of concepts introduced by earlier works in the Laplacian paradigm, such as effective resistances of edges, Schur complements, and graph (re)sparsification.</p>
<p>This workshop will survey the recent progress, with a focus on the rich connections exposed by the new ways of combining algorithmic constructs. The morning and afternoon sessions will focus on two overarching themes in these algorithms: the use of effective resistances in place of combinatorial graph theory, and the study of elimination-based algorithms on structured matrices.
</p></p>

<p><h style="font-size: 28px; font-weight: bold;">Schedule:</h></p>

<article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/richard/">Laplacian Paradigm 2.0: Merging Continuous and Discrete</a>
  </h3>
  <h4 style="color:#996600;"><a href="https://www.cc.gatech.edu/~rpeng/" target="_blank">Richard Peng (GaTech)</a> 08:40 -- 09:10</h4>
   <tag style="font-weight: bold;"> Abstract: </tag>  Over the past three decades, works related to efficient solvers for a class of graph structured matrices, graph Laplacians, led to fundamental results in combinatorial optimization and scientific computing as well as the Laplacian paradigm for graph algorithms. In this talk I’ll survey these progresses, with focus on the underlying algorithm design approaches. Specifically, I will discuss the origin of the Laplacian paradigm in combining combinatorial and numerical building blocks via spectral graph theory, and describe recent efforts on designing new tools tailored towards the overall algorithmic questions.
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/aaron/">Linear Algebraic Primitives Beyond Laplacian Solvers</a>
  </h3>
  <h4 style="color:#996600;"><a href="http://www.aaronsidford.com/" target="_blank">Aaron Sidford (Stanford)</a> 09:10 -- 09:50</h4>
   <tag style="font-weight: bold;"> Abstract: </tag>  Over the past decade nearly linear time Laplacian system solving has emerged as powerful algorithmic hammer in improving asymptotic running times of solving a wide variety of problems. Both the black-box application of Laplacian system solvers and the application of the algorithmic techniques underlying recent efficient Laplacian system solving algorithms have had broad implications in algorithm design. In this talk I will discuss recent progress in advancing this machinery beyond solving Laplacians systems towards solving broader classes of structured linear systems in nearly linear time. This talk will focus on recent advances in solving directed Laplacians (and more broadly M-matrices) in nearly linear time through efficient reductions to solving row-column diagonally dominant (RCDD) systems. Further, this talk will connect these problems to a variety of closely related linear algebraic problems including PageRank computation, policy evaluation, stationary distribution computation, Perron-Vectors computation, and more.
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/sushant/">Approximate Gaussian elimination and applications</a>
  </h3>
  <h4 style="color:#996600;"><a href="https://sachdevasushant.github.io/" target="_blank">Sushant Sachdeva (UToronto)</a> 09:50 -- 10:30</h4>
   <tag style="font-weight: bold;"> Abstract: </tag>  Gaussian elimination is the best known algorithm for solving systems of linear equations, and one of the oldest algorithms known. However, it is ill-suited for solving sparse systems since even for sparse Laplacian matrices, it can require running time that is super-quadratic in the input size. Several previous approaches speed up Gaussian elimination by introducing error, but fail to provide guarantees. Over the last few years, new versions of approximate Gaussian elimination have been developed for graph Laplacians that provide provable approximation guarantees, and run in time nearly-linear in the sparsity of the graph. In this talk, we will discuss these approaches, and how they lead to 1) simpler nearly-linear time Laplacian solvers, 2) nearly-linear time solvers for systems strictly more general than Laplacians, and 3) faster estimation of all pair effective resistances (which implies faster algorithms for estimating the determinant of a Laplacian).
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/morningbreak/">Morning Break</a>
  </h3>
  <h4 style="color:#996600;"><a href="" target="_blank"></a> 10:30 -- 11:00</h4>
   
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/rasmus/">Analysing approximate Gaussian elimination using matrix martingales</a>
  </h3>
  <h4 style="color:#996600;"><a href="http://rasmuskyng.com/" target="_blank">Rasmus Kyng (Harvard)</a> 11:00 -- 12:00</h4>
   <tag style="font-weight: bold;"> Abstract: </tag>  The sum of a sequence of random variables is a martingale, if each variable has zero mean, conditioned on all the preceding variables. Concentration results for matrix-valued martingales have become an important tool in the analysis of algorithms in randomized numerical linear algebra. Simple and fast algorithms for many well-studied problems can be analyzed in using martingales. We will explore recent results on using matrix martingales for analyzing approximate Gaussian elimination on Laplacian matrices associated with undirected and directed graphs, and survey briefly other uses of matrix martingales in spectral graph theory.
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/lunchbreak/">Lunch</a>
  </h3>
  <h4 style="color:#996600;"><a href="" target="_blank"></a> 12:00 -- 14:00</h4>
   
  
</article><article class="post">
  <h3 class="post-title">
    <a href="https://sachdevasushant.github.io/laplacian2.0/aaron_uc/">Algorithmic proofs via Gaussian elimination</a>
  </h3>
  <h4 style="color:#996600;"><a href="https://people.eecs.berkeley.edu/~aschild/" target="_blank">Aaron Schild (UC Berkeley)</a> 14:00 -- 15:00</h4>
   <tag style="font-weight: bold;"> Abstract: </tag>  TBD
  
</article>
</div>
    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-3519710-6', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  </body>
</html>
